<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content=""><title>大模型有关的一些工具链 | Kelin's blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/latest/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/grids-responsive-min.min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/latest/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><script type="text/javascript" src="//lib.baomitu.com/clipboard.js/latest/clipboard.min.js"></script><script type="text/javascript" src="//lib.baomitu.com/toastr.js/latest/toastr.min.js"></script><link rel="stylesheet" href="//lib.baomitu.com/toastr.js/latest/toastr.min.css"><meta name="generator" content="Hexo 6.3.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">大模型有关的一些工具链</h1><a id="logo" href="/.">Kelin's blog</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">大模型有关的一些工具链</h1><div class="post-meta">2024-11-07<span> | </span><span class="category"><a href="/categories/llvm/">llvm</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 1.7k</span><span class="post-meta-item-text"> Words</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i><span class="post-count"> 6</span><span class="post-meta-item-text"> Minutes</span></span></span></div><div class="post-content"><h2 id="使用大模型做具体场景助手"><a href="#使用大模型做具体场景助手" class="headerlink" title="使用大模型做具体场景助手"></a>使用大模型做具体场景助手</h2><p>使用开源工具来实现具体场景下的 AI 助手，流程可以简化如下：</p>
<ol>
<li><p>Prompt 工程</p>
<ul>
<li>流程：设计并优化 prompt，让大模型生成符合需求的答案，进行 prompt 测试和调整。</li>
<li>工具：可以使用 OpenAI API（如 GPT-3 开源替代品）结合 LangChain 或 LlamaIndex（前称 GPT Index）来管理和优化 prompt。</li>
</ul>
</li>
<li><p>构建知识库</p>
<ul>
<li>流程：收集和清洗数据，将信息分块后存入知识库，并生成索引以便高效检索。</li>
<li>工具：<ul>
<li>Elasticsearch 或 FAISS：用于分块后的数据存储和快速检索。</li>
<li>Haystack 或 LlamaIndex：可用于索引管理，便于与生成模型集成。</li>
</ul>
</li>
</ul>
</li>
<li><p>检索增强生成（RAG）</p>
<ul>
<li>流程：通过检索模块先找到相关信息片段，再输入生成模型生成回答，增强内容准确性。</li>
<li>工具：Haystack 或 LangChain，集成检索与生成，提供基于上下文的回答。</li>
</ul>
</li>
<li><p>大模型微调</p>
<ul>
<li>流程：将场景相关数据准备好后对大模型进行微调，使其适应具体领域或场景。</li>
<li>工具：<ul>
<li>Hugging Face Transformers：用于加载和微调模型。</li>
<li>Hugging Face Datasets：用于管理和预处理训练数据。</li>
</ul>
</li>
</ul>
</li>
<li><p>模型量化</p>
<ul>
<li>流程：在部署前对模型进行量化，以减小模型体积并加快推理速度。</li>
<li>工具：BitsAndBytes（4&#x2F;8 位量化）、ONNX Runtime（支持量化优化）。</li>
</ul>
</li>
<li><p>部署</p>
<ul>
<li>流程：将微调和量化后的模型部署在服务器或云端。</li>
<li>工具：<ul>
<li>FastAPI 或 Flask：用于搭建 API 服务。</li>
<li>Docker：用于容器化部署，保证环境一致性。</li>
<li>Hugging Face Inference（如使用推理服务器）或 ONNX Runtime（加速推理）。</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>简化流程示例</p>
<p>设计 prompt → 构建知识库 → RAG 检索 → 大模型微调 → 模型量化 → 部署</p>
<p>这些步骤结合开源工具能够实现高效的 AI 助手。</p>
<h2 id="ollama"><a href="#ollama" class="headerlink" title="ollama"></a>ollama</h2><h3 id="ollama简介"><a href="#ollama简介" class="headerlink" title="ollama简介"></a>ollama简介</h3><p>ollama用来部署和运行大型语言模型，它提供了一个简单的命令行工具，可以用来运行模型、查看模型列表、下载模型等。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">设计 prompt → 构建知识库 → RAG 检索 → Ollama 微调 → Ollama 量化 → Ollama 部署</span><br></pre></td></tr></table></figure>

<p>官网地址：<a target="_blank" rel="noopener" href="https://ollama.com/">ollama</a></p>
<h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><p>运行一个模型，如果本地不存在该模型，会自动到仓库下载，仓库地址：<br><a target="_blank" rel="noopener" href="https://ollama.com/library">ollama模型仓库</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ollama run llama3-8b-8192</span><br></pre></td></tr></table></figure>

<p>一些指令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看模型列表</span></span><br><span class="line">ollama list</span><br><span class="line"><span class="comment"># 查看当前运行的模型</span></span><br><span class="line">ollama ps</span><br><span class="line"></span><br><span class="line"><span class="comment"># -h 查看帮助</span></span><br><span class="line">serve       Start ollama</span><br><span class="line">create      Create a model from a Modelfile</span><br><span class="line">show        Show information <span class="keyword">for</span> a model</span><br><span class="line">run         Run a model</span><br><span class="line">stop        Stop a running model</span><br><span class="line">pull        Pull a model from a registry</span><br><span class="line">push        Push a model to a registry</span><br><span class="line">list        List models</span><br><span class="line">ps          List running models</span><br><span class="line"><span class="built_in">cp</span>          Copy a model</span><br><span class="line"><span class="built_in">rm</span>          Remove a model</span><br><span class="line"><span class="built_in">help</span>        Help about any <span class="built_in">command</span></span><br></pre></td></tr></table></figure>

<p>查看ollama是否正确启动：<a target="_blank" rel="noopener" href="http://127.0.0.1:11434/">http://127.0.0.1:11434</a></p>
<h2 id="open-webui"><a href="#open-webui" class="headerlink" title="open-webui"></a>open-webui</h2><p>open-webui提供了一个简单的web界面，可以用来查看模型列表、运行模型等。</p>
<p>仓库地址：<a target="_blank" rel="noopener" href="https://github.com/open-webui/open-webui">open-webui</a></p>
<h3 id="安装和使用"><a href="#安装和使用" class="headerlink" title="安装和使用"></a>安装和使用</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install open-webui</span><br><span class="line">open-webui serve</span><br></pre></td></tr></table></figure>

<h2 id="modelscope"><a href="#modelscope" class="headerlink" title="modelscope"></a>modelscope</h2><p>官网地址：<a target="_blank" rel="noopener" href="https://modelscope.ai/">modelscope</a></p>
<p>github地址：<a target="_blank" rel="noopener" href="https://github.com/modelscope/modelscope/tree/master">modelscope</a></p>
<h3 id="modelscope简介"><a href="#modelscope简介" class="headerlink" title="modelscope简介"></a>modelscope简介</h3><p>modelscope是一个 “模型即服务”(MaaS) 平台，旨在汇集来自 AI 社区的最先进的机器学习模型，并简化在实际应用中使用 AI 模型的流程。ModelScope 库使开发人员能够通过丰富的 API 设计执行推理、训练和评估，从而促进跨不同 AI 领域的最先进模型的统一体验。</p>
<p>ModelScope Library 为模型贡献者提供了必要的分层 API，以便将来自 CV、NLP、语音、多模态以及科学计算的模型集成到 ModelScope 生态系统中。所有这些不同模型的实现都以一种简单统一访问的方式进行封装，用户只需几行代码即可完成模型推理、微调和评估。同时，灵活的模块化设计使得在必要时也可以自定义模型训练推理过程中的不同组件。</p>
<h3 id="安装和使用-1"><a href="#安装和使用-1" class="headerlink" title="安装和使用"></a>安装和使用</h3><p>在ModelScope Hub 中有很多可以训练的模型。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda create -n modelscope python=3.10</span><br><span class="line">conda activate modelscope</span><br></pre></td></tr></table></figure>

<p>模型下载需要先配置好Git LFS。</p>
<blockquote>
<p>git lfs 是一个 Git 的扩展，它用来存储大文件。它的设计目标是让 Git 能够更好地管理大文件，而不是让 Git 成为一个文件存储系统。Git LFS 通过将大文件存储在远程服务器上，而不是存储在 Git 仓库中，来解决 Git 仓库过大的问题。</p>
</blockquote>
<p>之后就可以下载用来训练的模型，和github上的代码一样，可以直接使用git clone。</p>
<p>训练好的模型（微调）在部署时，通常还需要量化，这样才能在较小的设备上运行。</p>
<h2 id="langchain和langchain-chatchat"><a href="#langchain和langchain-chatchat" class="headerlink" title="langchain和langchain-chatchat"></a>langchain和langchain-chatchat</h2><p>langchain是一个用于构建自然语言处理（NLP）应用的工具包。它提供了一种简单的方法来构建NLP应用，无需编写复杂的代码。langchain的核心是一个称为“链”的概念，链是一系列处理步骤，每个步骤都接收输入并生成输出。链可以包含各种处理步骤，例如模型、解析器和提示。</p>
<p>这里有一个简单的教程:<a target="_blank" rel="noopener" href="https://www.langchain.com.cn/docs/tutorials/llm_chain/">langchain</a>，可以用来构建一个简单的LLM（Large Language Model）应用。</p>
<p>核心就是构建链，链可以包含各种处理步骤，例如模型、解析器和提示。</p>
<h3 id="langchain-chatchat"><a href="#langchain-chatchat" class="headerlink" title="langchain-chatchat"></a>langchain-chatchat</h3><p>仓库地址：<a target="_blank" rel="noopener" href="https://github.com/chatchat-space/Langchain-Chatchat?tab=readme-ov-files">langchain-chatchat</a></p>
<p>一种利用 langchain 思想实现的基于本地知识库的问答应用，目标期望建立一套对中文场景与开源模型支持友好、可离线运行的知识库问答解决方案。</p>
<p><strong>原理：</strong><br><img src="/../imgs/image-65.png"><br><img src="/../imgs/image-66.png"></p>
<p>在这个项目中，并不涉及模型的微调。模型微调参考：<a href="https://kelinkong.github.io/2024/11/01/llvm-%E5%BE%AE%E8%B0%83%E5%A4%A7%E6%A8%A1%E5%9E%8B/">llvm-微调大模型</a></p>
<h2 id="Dify"><a href="#Dify" class="headerlink" title="Dify"></a>Dify</h2><p>官网地址：<a target="_blank" rel="noopener" href="https://www.dify.ai/">Dify</a></p>
<p>github地址：<a target="_blank" rel="noopener" href="https://github.com/langgenius/dify">Dify</a></p>
<p>官方文档：<a target="_blank" rel="noopener" href="https://docs.dify.ai/">Dify文档</a></p>
<p>Dify 是一款开源的大语言模型(LLM) 应用开发平台。它融合了后端即服务（Backend as Service）和 LLMOps 的理念，使开发者可以快速搭建生产级的生成式 AI 应用。即使你是非技术人员，也能参与到 AI 应用的定义和数据运营过程中。</p>
<p>由于 Dify 内置了构建 LLM 应用所需的关键技术栈，包括对数百个模型的支持、直观的 Prompt 编排界面、高质量的 RAG 引擎、稳健的 Agent 框架、灵活的流程编排，并同时提供了一套易用的界面和 API。这为开发者节省了许多重复造轮子的时间，使其可以专注在创新和业务需求上。</p>
<p>dify支持ollama，可以直接使用本地部署的模型。</p>
<h2 id="Groqcloud"><a href="#Groqcloud" class="headerlink" title="Groqcloud"></a>Groqcloud</h2><p>官网地址：<a target="_blank" rel="noopener" href="https://console.groq.com/playground">Groqcloud</a></p>
<p>GroqCloud 是由 Groq 公司提供的云服务，专注于快速 AI 推理。它利用 Groq 的语言处理单元（LPU）硬件和相关软件，推理速度很快，而且API便宜。</p>
</div><div class="tags"></div><div class="post-nav"><a class="pre" href="/2024/11/07/lvvm-%E4%BD%BF%E7%94%A8langchain-chatchat%E5%92%8Collama%E6%9E%84%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B/">llvm-使用langchain-chatchat和ollama构建大模型</a><a class="next" href="/2024/11/06/%E4%BD%BF%E7%94%A8-LCEL-%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84-LLM-%E5%BA%94%E7%94%A8/">使用 LCEL 构建一个简单的 LLM 应用</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://kelinkong.github.io"/></form></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="About"><img class="nofancybox" src="/img/logo.jpg"/></a><p>Kelin is a boring girl, but not always.</p><a class="info-icon" href="https://github.com/kelinkong" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Algorithm/">Algorithm</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/CPP/">CPP</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/DataBase/">DataBase</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Frontend/">Frontend</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Java/">Java</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/LLVM/">LLVM</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Math/">Math</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Network-Security/">Network Security</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Operating-System/">Operating System</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Solutions/">Solutions</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/frontend/">frontend</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/llvm/">llvm</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/CMU15-445/" style="font-size: 15px;">CMU15-445</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/CPP/" style="font-size: 15px;">CPP</a> <a href="/tags/note/" style="font-size: 15px;">note</a> <a href="/tags/architecture/" style="font-size: 15px;">architecture</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2024/11/07/lvvm-%E4%BD%BF%E7%94%A8langchain-chatchat%E5%92%8Collama%E6%9E%84%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B/">llvm-使用langchain-chatchat和ollama构建大模型</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/11/07/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%9C%89%E5%85%B3%E7%9A%84%E4%B8%80%E4%BA%9B%E5%B7%A5%E5%85%B7%E9%93%BE/">大模型有关的一些工具链</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/11/06/%E4%BD%BF%E7%94%A8-LCEL-%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84-LLM-%E5%BA%94%E7%94%A8/">使用 LCEL 构建一个简单的 LLM 应用</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/11/01/llvm-%E5%BE%AE%E8%B0%83%E5%A4%A7%E6%A8%A1%E5%9E%8B/">llvm-微调大模型</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/10/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/">机器学习基础</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/10/23/Spring-Boot%EF%BC%9ASpring-MVC/">Spring Boot：Spring MVC</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/10/22/Spring-Boot%EF%BC%9A%E4%BA%8B%E5%8A%A1%E5%A4%84%E7%90%86/">Spring Boot：事务处理</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/10/22/Java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-MyBatis/">Java学习笔记-MyBatis</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/10/22/Spring-Boot%EF%BC%9A%E5%85%A8%E6%B3%A8%E8%A7%A3%E4%B8%8B%E7%9A%84loc/">Spring Boot：全注解下的IoC</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/10/18/llvm-%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">llvm学习-人工神经网络</a></li></ul></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2024 <a href="/." rel="nofollow">Kelin's blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.js"></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0"></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.css"><script type="text/javascript" src="/js/love.js?v=1.0.0"></script><script type="text/javascript" src="/js/copycode.js?v=1.0.0" successtext="Copy Successed!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css?v=1.0.0"><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html><!-- 插入 Dify 大模型助手代码--><script>window.difyChatbotConfig = {
  token: '4gcHypq3JpvHcBxt'
}</script><script src="https://udify.app/embed.min.js" id="4gcHypq3JpvHcBxt" defer></script><style>#dify-chatbot-bubble-button {
  background-color: #1C64F2 !important;
  position: fixed !important;
  bottom: 20px !important;
  left: 20px !important;
}
#dify-chatbot-bubble-window {
  width: 24rem !important;
  height: 40rem !important;
  bottom: 70px !important; /* 确保窗口在按钮上方 */
  left: 20px !important;
}</style>