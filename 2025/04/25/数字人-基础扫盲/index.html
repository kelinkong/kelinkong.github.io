<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content=""><title>数字人-基础扫盲 | Kelin's blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/latest/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/grids-responsive-min.min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/latest/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><script type="text/javascript" src="//lib.baomitu.com/clipboard.js/latest/clipboard.min.js"></script><script type="text/javascript" src="//lib.baomitu.com/toastr.js/latest/toastr.min.js"></script><link rel="stylesheet" href="//lib.baomitu.com/toastr.js/latest/toastr.min.css"><meta name="generator" content="Hexo 6.3.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">数字人-基础扫盲</h1><a id="logo" href="/.">Kelin's blog</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">数字人-基础扫盲</h1><div class="post-meta">2025-04-25<span> | </span><span class="category"><a href="/categories/Digital-Human/">Digital Human</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 1.6k</span><span class="post-meta-item-text"> Words</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i><span class="post-count"> 5</span><span class="post-meta-item-text"> Minutes</span></span></span></div><div class="post-content"><h2 id="数字人模型">数字人模型</h2>
<h3 id="什么是数字人模型？">什么是数字人模型？</h3>
<p>“虚拟数字人模型”是近年来非常热门的一个概念，它结合了人工智能、计算机图形学、语音合成、自然语言处理等技术，用来创建和驱动一个在视觉、语音和行为上都像真人一样的“数字人”。</p>
<h4 id="核心构成模块">核心构成模块</h4>
<ol>
<li>
<p><strong>视觉模型（Avatar生成）</strong></p>
<ul>
<li>用来生成虚拟人的三维形象（2D 或 3D）</li>
<li>可以使用：Unity、Unreal Engine、MetaHuman、Blender 等工具</li>
<li>技术支持：计算机图形学、人脸建模、动作捕捉</li>
</ul>
</li>
<li>
<p><strong>语音模型（TTS &amp; ASR）</strong></p>
<ul>
<li>TTS：文字转语音（Text to Speech）</li>
<li>ASR：语音识别（Automatic Speech Recognition）</li>
</ul>
</li>
<li>
<p><strong>语言理解与生成模型（NLP）</strong></p>
<ul>
<li>负责理解用户说的话，生成合适的回应</li>
<li>如：GPT、ChatGLM、BERT 等大语言模型</li>
<li>也包含意图识别、情感识别、对话管理等</li>
</ul>
</li>
<li>
<p><strong>行为驱动模型（动画与情绪联动）</strong></p>
<ul>
<li>根据语音和文本生成对应的面部表情和动作</li>
<li>技术：表情驱动（facial animation）、骨骼动画、AI驱动的姿态识别</li>
</ul>
</li>
<li>
<p><strong>知识图谱 / 记忆系统（可选）</strong></p>
<ul>
<li>帮助数字人拥有长期记忆、个性化推荐能力</li>
</ul>
</li>
</ol>
<h4 id="常见技术栈">常见技术栈</h4>
<ul>
<li><strong>语言处理</strong>：OpenAI GPT、ChatGLM、BERT、Rasa</li>
<li><strong>语音合成/识别</strong>：科大讯飞、腾讯云、百度语音、微软 Azure</li>
<li><strong>3D建模</strong>：MetaHuman、Unreal Engine、Unity</li>
<li><strong>驱动引擎</strong>：Unity、UE + Python/JS 脚本控制</li>
<li><strong>集成平台</strong>：D-ID、Synthesia、Alibaba数字人平台等</li>
</ul>
<h3 id="常用的数字人模型有哪些？">常用的数字人模型有哪些？</h3>
<table>
<thead>
<tr>
<th>模型类别</th>
<th>代表模型</th>
<th>用途说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>🌐 语言模型（NLP）</td>
<td>ChatGPT / GPT-4 / ChatGLM / Mistral / LLaMA</td>
<td>处理自然语言对话，生成内容</td>
</tr>
<tr>
<td>🔊 语音合成模型（TTS）</td>
<td>FastSpeech、VITS、Edge TTS、科大讯飞语音</td>
<td>将文本转成语音，表达情绪语调</td>
</tr>
<tr>
<td>🎙️ 语音识别模型（ASR）</td>
<td>Whisper、腾讯云语音识别、百度ASR</td>
<td>将用户语音转成文字，供语言模型处理</td>
</tr>
<tr>
<td>😃 表情/驱动模型</td>
<td>Audio2Face、DeepMotion、Faceware</td>
<td>根据语音驱动面部表情、动作</td>
</tr>
<tr>
<td>🧠 多模态模型</td>
<td>GPT-4V、CLIP、Flamingo</td>
<td>让数字人具备图文混合理解与生成能力</td>
</tr>
</tbody>
</table>
<h2 id="LiveTalking学习">LiveTalking学习</h2>
<p>仓库地址：<a target="_blank" rel="noopener" href="https://github.com/lipku/LiveTalking">LiveTalking</a></p>
<p>LiveTalking是一个基于数字人技术开发的实时语音交互平台，它允许用户与数字人进行实时语音交互，并实时展示数字人的表情和动作。</p>
<h3 id="项目运行的流程">项目运行的流程</h3>
<p>在<code>app.py</code></p>
<p>在if <strong>name</strong> == ‘<strong>main</strong>’:块中，首先通过argparse.ArgumentParser()解析命令行参数。这些参数控制模型类型、传输协议（如WebRTC、RTMP等）、音频处理选项、TTS服务器地址等。</p>
<p>加载模型和头像 根据选择的模型类型（opt.model），从不同的模块（如ernerf、musetalk、wav2lip）加载相应的模型和头像。</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>一句话功能定位</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ER-NeRF</strong></td>
<td>高保真的<strong>3D人脸建模和渲染</strong></td>
</tr>
<tr>
<td><strong>MUSE-Talk</strong></td>
<td>基于音频的<strong>语音驱动唇形动画生成</strong>（多情绪）</td>
</tr>
<tr>
<td><strong>Wav2Lip</strong></td>
<td>基于音频的<strong>视频嘴型对齐模型</strong></td>
</tr>
<tr>
<td><strong>Ultralight Digital Human</strong></td>
<td>全流程数字人系统：<strong>轻量建模 + 驱动合成</strong></td>
</tr>
</tbody>
</table>
<h4 id="📊-功能与特性对比表">📊 功能与特性对比表</h4>
<table>
<thead>
<tr>
<th>项目</th>
<th><strong>ER-NeRF</strong></th>
<th><strong>MUSE-Talk</strong></th>
<th><strong>Wav2Lip</strong></th>
<th><strong>Ultralight-Digital-Human</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>类型</td>
<td>NeRF建模</td>
<td>动画生成（头部）</td>
<td>嘴型对齐（视频增强）</td>
<td>全栈式数字人引擎</td>
</tr>
<tr>
<td>输入</td>
<td>多视角照片 + 音频</td>
<td>音频（可选图像）</td>
<td>视频 + 音频</td>
<td>语音/文本 + 图像</td>
</tr>
<tr>
<td>输出</td>
<td>高精度3D人脸</td>
<td>带嘴型动画的头像视频</td>
<td>嘴型对齐修正后视频</td>
<td>数字人口播视频</td>
</tr>
<tr>
<td>是否3D</td>
<td>✅（NeRF）</td>
<td>❌（伪3D/2D）</td>
<td>❌</td>
<td>可2D或伪3D</td>
</tr>
<tr>
<td>表情/情绪控制</td>
<td>✅</td>
<td>✅（multi-style）</td>
<td>❌</td>
<td>支持一定表情合成</td>
</tr>
<tr>
<td>实时性</td>
<td>❌（较慢）</td>
<td>❌（需预处理）</td>
<td>✅（较快）</td>
<td>✅（轻量）</td>
</tr>
<tr>
<td>模型体积</td>
<td>大</td>
<td>中等</td>
<td>小</td>
<td>小（可部署）</td>
</tr>
<tr>
<td>是否可商用</td>
<td>❌ 研究为主</td>
<td>❌ 研究为主</td>
<td>✅（MIT开源）</td>
<td>✅（商用可谈）</td>
</tr>
<tr>
<td>适用方向</td>
<td>数字人建模/高保真渲染</td>
<td>虚拟主播嘴型动画</td>
<td>提升对口型视频真实感</td>
<td>快速构建轻量数字人客服等</td>
</tr>
</tbody>
</table>
<p><strong>“口型驱动模型”只是构建数字人的一小部分，而 LiveTalking 是把语音输入 → 模型推理 → 视频输出 → 播放/控制 这整条流程封装起来的完整运行框架。</strong></p>
<h2 id="LatentSync学习">LatentSync学习</h2>
<p>仓库地址：<a target="_blank" rel="noopener" href="https://github.com/bytedance/LatentSync">LatentSync</a></p>
<p><code>scripts/inference.py</code>代码的核心解析，这是LatentSync项目的<strong>模型推理核心实现</strong>，实现了音视频同步生成的完整处理流程：</p>
<hr>
<h3 id="一、代码核心架构">一、代码核心架构</h3>
<table>
<thead>
<tr>
<th>模块</th>
<th>功能说明</th>
<th>关键技术</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>音频编码器</strong></td>
<td>通过Whisper模型提取音频特征</td>
<td><code>Audio2Feature</code>类实现</td>
</tr>
<tr>
<td><strong>VAE</strong></td>
<td>视频潜在空间编码/解码</td>
<td>StabilityAI的<code>sd-vae-ft-mse</code></td>
</tr>
<tr>
<td><strong>UNet3D</strong></td>
<td>时空特征融合与去噪</td>
<td>3D条件扩散模型</td>
</tr>
<tr>
<td><strong>推理管线</strong></td>
<td>协调各模块完成生成流程</td>
<td><code>LipsyncPipeline</code>类</td>
</tr>
</tbody>
</table>
<h3 id="二、关键代码流程">二、关键代码流程</h3>
<h4 id="1-初始化阶段">1. 初始化阶段</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 选择计算精度（根据GPU能力自动切换FP16/FP32）</span></span><br><span class="line">is_fp16_supported = torch.cuda.get_device_capability()[<span class="number">0</span>] &gt; <span class="number">7</span></span><br><span class="line">dtype = torch.float16 <span class="keyword">if</span> is_fp16_supported <span class="keyword">else</span> torch.float32</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载扩散模型调度器</span></span><br><span class="line">scheduler = DDIMScheduler.from_pretrained(<span class="string">&quot;configs&quot;</span>)  <span class="comment"># 使用DDIM加速采样</span></span><br></pre></td></tr></table></figure>
<h4 id="2-模型加载">2. 模型加载</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 音频特征提取器（根据cross_attention_dim选择模型规模）</span></span><br><span class="line">audio_encoder = Audio2Feature(</span><br><span class="line">    model_path=<span class="string">&quot;checkpoints/whisper/tiny.pt&quot;</span>,  <span class="comment"># 384维特征</span></span><br><span class="line">    num_frames=config.data.num_frames,         <span class="comment"># 视频帧数（如16帧）</span></span><br><span class="line">    audio_feat_length=config.data.audio_feat_length  <span class="comment"># 音频特征长度</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 图像潜在空间编解码器</span></span><br><span class="line">vae = AutoencoderKL.from_pretrained(<span class="string">&quot;stabilityai/sd-vae-ft-mse&quot;</span>)</span><br><span class="line">vae.config.scaling_factor = <span class="number">0.18215</span>  <span class="comment"># 潜在空间缩放系数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3D UNet去噪模型</span></span><br><span class="line">denoising_unet = UNet3DConditionModel.from_pretrained(</span><br><span class="line">    config=OmegaConf.to_container(config.model),  <span class="comment"># 模型结构配置</span></span><br><span class="line">    ckpt_path=args.inference_ckpt_path            <span class="comment"># 预训练权重</span></span><br><span class="line">).to(dtype=dtype)</span><br></pre></td></tr></table></figure>
<h4 id="3-推理管线构建">3. 推理管线构建</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">pipeline = LipsyncPipeline(</span><br><span class="line">    vae=vae,                   <span class="comment"># 潜在空间编解码</span></span><br><span class="line">    audio_encoder=audio_encoder,  <span class="comment"># 音频特征提取</span></span><br><span class="line">    denoising_unet=denoising_unet,  <span class="comment"># 时空去噪</span></span><br><span class="line">    scheduler=scheduler         <span class="comment"># 扩散调度策略</span></span><br><span class="line">).to(<span class="string">&quot;cuda&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="4-生成执行">4. 生成执行</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">pipeline(</span><br><span class="line">    video_path=args.video_path,  <span class="comment"># 输入视频（驱动姿态）</span></span><br><span class="line">    audio_path=args.audio_path,  <span class="comment"># 输入音频（驱动唇形）</span></span><br><span class="line">    video_out_path=args.video_out_path,  <span class="comment"># 输出视频路径</span></span><br><span class="line">    num_inference_steps=args.inference_steps,  <span class="comment"># 去噪步数（默认20）</span></span><br><span class="line">    guidance_scale=args.guidance_scale,  <span class="comment"># 分类器自由引导强度（默认1.0）</span></span><br><span class="line">    width=config.data.resolution,  <span class="comment"># 输出分辨率（如512）</span></span><br><span class="line">    mask_image_path=config.data.mask_image_path  <span class="comment"># 面部区域掩码</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="三、关键参数说明">三、关键参数说明</h3>
<table>
<thead>
<tr>
<th>参数</th>
<th>作用</th>
<th>典型值</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>num_inference_steps</code></td>
<td>控制生成质量与速度的平衡</td>
<td>20-50步</td>
</tr>
<tr>
<td><code>guidance_scale</code></td>
<td>调节音频条件对生成的引导强度</td>
<td>1.0-3.0</td>
</tr>
<tr>
<td><code>num_frames</code></td>
<td>同时处理的视频帧数</td>
<td>16帧</td>
</tr>
<tr>
<td><code>resolution</code></td>
<td>输出视频分辨率</td>
<td>512x512</td>
</tr>
</tbody>
</table>
</div><script type="text/javascript" src="/js/share.js?v=1.0.0" async></script><a class="article-share-link" data-url="https://kelinkong.github.io/2025/04/25/%E6%95%B0%E5%AD%97%E4%BA%BA-%E5%9F%BA%E7%A1%80%E6%89%AB%E7%9B%B2/" data-id="cmbuhqyz4004gz4ogaxbs6mrk" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPYAAAD2CAAAAADAeSUUAAADO0lEQVR42u3aS27bQBAFQN3/0g6QVQJI9Hs9MmC2iivDIodTo0WrP49HfH39vV795+ufK1/na3S9WufxExc2Njb2Tdjta65ffH0c129Jjjt/4zdvwcbGxl7Hfm+wyde/Puj809yCjY2N/cns68SjXafNFJJPsbGxsbHzAJZv8TqZyYPfybFiY2NjfwI7/+nfNg/yhCRPQtpnsbGxsXez20bvb/77B/vb2NjY2L+SfVL0PwmBSThs7ykU2NjY2IvYs7QhSSTOh2yS4JSkTC9XwMbGxl7Hno3gJJ8mW2+DXPvl1bU0bGxs7JuwZ0X8k4J72zBuE5uovYGNjY29lF0MuwQ/+vOVk+PL3xWVpbCxsbGXsq8faMdockCelszaz0/ux8bGxl7HPmm75mX9WeKRh7eisIWNjY29iD3b+ow0ayEUpaI2pGFjY2MvYiekNknIDzRvLbeN52h8BxsbG/vm7BkmD13tps+buNGhYGNjY69jzxZqk4STUJQ3nqMdYmNjYy9inzRiT9KS2ebyZKY9SmxsbOy7s5NQlJeN8nDYBshZoerRbh0bGxv7VuwceX4c+ZBNe2f9LDY2NvY6dtt8TZoHbennJDQOxy6xsbGxV7BPhmzy4k47oHNS3pq1FrCxsbE3sdtG70nz4PwI2j0Mwxg2Njb2TdjJT/zhD/1RWSpvD7eHiI2Njb2JnQeVWfjJG7Ht6E9b0vpvZWxsbOx17DwZmGU2bQqRHNAjvl52RbCxsbFXsPOi0iwBaJu17ZjmrGGMjY2NvYn9c+M4swJW+40lR/PkfmxsbOzV7FlLIA9aJ8FsFuqe7BkbGxt7EfukZZuHn9n4ziyXKsIbNjY29gr2bPClngYaHd/JEXwTaLGxsbHXsduW6vU9J2lGnqicHCs2Njb2PvZ7X98+m/wnIRX7xMbGxl7EflfaMEsP8jQjP7jkK8HGxsbex54FreSpNgk5GRVK3v5oAdjY2Ni3Yrc/9/MX5EM/eQv5zWkGNjY29sewk2JQHpbykJncmY/yYGNjY2PPkO8Cv+sgsLGxsfex84WuV8ipJ8WpvHUxHNzBxsbGvhV71ug9SVRmgzhtk7htA2NjY2PfkP0Hk52M4F1LkPYAAAAASUVORK5CYII=">Share</a><div class="tags"></div><div class="post-nav"><a class="pre" href="/2025/05/21/%E6%95%B0%E5%AD%97%E4%BA%BA-Java%E9%9F%B3%E8%A7%86%E9%A2%91%E5%A4%84%E7%90%86/">数字人-Java音视频处理-推流和拉流</a><a class="next" href="/2025/04/18/Java-%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/">Java-基础学习</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://kelinkong.github.io"/></form></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="About"><img class="nofancybox" src="/img/logo.jpg"/></a><p>Kelin is a boring girl, but not always.</p><a class="info-icon" href="https://github.com/kelinkong" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/AI/">AI</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Algorithm/">Algorithm</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/C/">C++</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/DataBase/">DataBase</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Digital-Human/">Digital Human</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Frontend/">Frontend</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Java/">Java</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Network-Security/">Network-Security</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Operating-System/">Operating-System</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Radar-Principle/">Radar Principle</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/frontend/">frontend</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/solutions/">solutions</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/architecture/" style="font-size: 15px;">architecture</a> <a href="/tags/CMU15-445/" style="font-size: 15px;">CMU15-445</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/%E9%9B%B7%E8%BE%BE%E5%8E%9F%E7%90%86/" style="font-size: 15px;">雷达原理</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2025/06/13/%E9%9B%B7%E8%BE%BE%E5%8E%9F%E7%90%86-%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E5%99%A8%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/">雷达原理-卡尔曼滤波器基础学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/06/05/Java-Java%E7%9A%84%E5%AE%B9%E5%99%A8%E5%92%8CC-%E7%9A%84STL%E5%AE%B9%E5%99%A8%E7%9A%84%E5%AF%B9%E6%AF%94/">Java-Java的容器和C++的STL容器的对比</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/06/05/%E6%95%B0%E5%AD%97%E4%BA%BA-Java%E9%9F%B3%E8%A7%86%E9%A2%91%E5%A4%84%E7%90%86-%E9%9F%B3%E9%A2%91%E6%8E%A8%E6%B5%81%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/">数字人-Java音视频处理-音频推流失败问题排查</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/05/21/%E6%95%B0%E5%AD%97%E4%BA%BA-Java%E9%9F%B3%E8%A7%86%E9%A2%91%E5%A4%84%E7%90%86/">数字人-Java音视频处理-推流和拉流</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/04/25/%E6%95%B0%E5%AD%97%E4%BA%BA-%E5%9F%BA%E7%A1%80%E6%89%AB%E7%9B%B2/">数字人-基础扫盲</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/04/18/Java-%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/">Java-基础学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/02/13/deepseek-v3%E6%8A%80%E6%9C%AF%E6%8A%A5%E5%91%8A%E5%AD%A6%E4%B9%A0/">deepseek-v3技术报告学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/01/10/DB-%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93Neo4j/">DB-图数据库Neo4j</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/01/09/Java-%E7%BC%96%E8%AF%91%E7%9B%B8%E5%85%B3/">Java-编译相关</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/12/27/AI-%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E7%AC%94%E8%AE%B0/">AI-动手学深度学习-笔记</a></li></ul></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2025 <a href="/." rel="nofollow">Kelin's blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.js"></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0"></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.css"><script type="text/javascript" src="/js/love.js?v=1.0.0"></script><script type="text/javascript" src="/js/copycode.js?v=1.0.0" successtext="Copy Successed!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css?v=1.0.0"><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>